{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Red Wine Quality Dataset Analysis\n",
                "\n",
                "This notebook analyzes the **Red Wine Quality** dataset from the UCI Machine Learning Repository. The goal is to predict the quality of red wine based on various physicochemical properties.\n",
                "\n",
                "### Dataset Description\n",
                "- **Number of Instances:** 1,599\n",
                "- **Number of Attributes:** 11 input variables + 1 output variable (quality)\n",
                "- **Attributes:**\n",
                "    1. `fixed acidity`: Most acids involved with wine are fixed or nonvolatile (do not evaporate readily).\n",
                "    2. `volatile acidity`: The amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste.\n",
                "    3. `citric acid`: Found in small quantities, citric acid can add 'freshness' and flavor to wines.\n",
                "    4. `residual sugar`: The amount of sugar remaining after fermentation stops.\n",
                "    5. `chlorides`: The amount of salt in the wine.\n",
                "    6. `free sulfur dioxide`: The free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine.\n",
                "    7. `total sulfur dioxide`: Amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine.\n",
                "    8. `density`: The density of wine is close to that of water depending on the percent alcohol and sugar content.\n",
                "    9. `pH`: Describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale.\n",
                "    10. `sulphates`: A wine additive which can contribute to sulfur dioxide gas (S02) levels, which acts as an antimicrobial and antioxidant.\n",
                "    11. `alcohol`: The percent alcohol content of the wine.\n",
                "- **Output variable (target):**\n",
                "    12. `quality`: Score between 0 and 10 (based on sensory data)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import fetch_openml\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "# Set style for visualizations\n",
                "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
                "plt.rcParams['figure.figsize'] = (10, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the Red Wine Quality dataset from OpenML\n",
                "print(\"Loading dataset...\")\n",
                "wine_data = fetch_openml(name='wine-quality-red', version=1, as_frame=True)\n",
                "df = wine_data.frame\n",
                "\n",
                "# Display first few rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic stats\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of Target variable (Quality)\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.countplot(x='class', data=df)\n",
                "plt.title('Distribution of Wine Quality (Target)')\n",
                "plt.xlabel('Quality Score')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation Heatmap\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
                "plt.title('Correlation Matrix of Wine Attributes')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Boxplots to see relationship between alcohol and quality\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='class', y='alcohol', data=df)\n",
                "plt.title('Alcohol vs. Wine Quality')\n",
                "plt.xlabel('Quality')\n",
                "plt.ylabel('Alcohol Content (%)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split features and target\n",
                "X = df.drop('class', axis=1)\n",
                "y = df['class'].astype(int) # Ensure target is integer for classification\n",
                "\n",
                "# Scaling features\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "# Split into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(f\"Training set shape: {X_train.shape}\")\n",
                "print(f\"Testing set shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modeling (6 Models Comparison)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000, multi_class='auto'),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "    'SVC': SVC(probability=True, random_state=42),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
                "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
                "    'KNN': KNeighborsClassifier()\n",
                "}\n",
                "\n",
                "results = {}\n",
                "print(\"Training and evaluating 6 models...\")\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    results[name] = acc\n",
                "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
                "\n",
                "# Select top 4 models\n",
                "sorted_models = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
                "top_4_names = [name for name, acc in sorted_models[:4]]\n",
                "print(f\"\\nTop 4 models: {top_4_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Hyperparameter Tuning & Ensemble"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Tuning top 4 models...\")\n",
                "\n",
                "tuned_models = []\n",
                "\n",
                "# Define parameter grids for the top 4 candidates (assuming RF, Extra Trees, SVC, and Gradient Boosting are typically top)\n",
                "param_grids = {\n",
                "    'Random Forest': {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'max_depth': [None, 10, 20],\n",
                "        'min_samples_split': [2, 5]\n",
                "    },\n",
                "    'Extra Trees': {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'max_depth': [None, 10, 20]\n",
                "    },\n",
                "    'SVC': {\n",
                "        'C': [0.1, 1, 10],\n",
                "        'gamma': ['scale', 'auto'],\n",
                "        'kernel': ['rbf', 'poly']\n",
                "    },\n",
                "    'Gradient Boosting': {\n",
                "        'n_estimators': [100, 200],\n",
                "        'learning_rate': [0.01, 0.1, 0.2]\n",
                "    },\n",
                "    'Logistic Regression': {\n",
                "        'C': [0.1, 1, 10]\n",
                "    },\n",
                "    'KNN': {\n",
                "        'n_neighbors': [3, 5, 11]\n",
                "    }\n",
                "}\n",
                "\n",
                "for name in top_4_names:\n",
                "    print(f\"Tuning {name}...\")\n",
                "    base_model = models[name]\n",
                "    grid = GridSearchCV(base_model, param_grids[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
                "    grid.fit(X_train, y_train)\n",
                "    tuned_models.append((name, grid.best_estimator_))\n",
                "    print(f\"Best params for {name}: {grid.best_params_}\")\n",
                "\n",
                "# Create Ensemble (Voting Classifier)\n",
                "print(\"\\nCreating soft voting ensemble...\")\n",
                "ensemble = VotingClassifier(estimators=tuned_models, voting='soft')\n",
                "ensemble.fit(X_train, y_train)\n",
                "\n",
                "y_pred_ens = ensemble.predict(X_test)\n",
                "print(f\"Ensemble Accuracy: {accuracy_score(y_test, y_pred_ens):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Final Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Final Evaluation of Ensemble Model:\\n\")\n",
                "print(classification_report(y_test, y_pred_ens))\n",
                "\n",
                "# Confusion Matrix Heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "cm = confusion_matrix(y_test, y_pred_ens)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
                "plt.title('Confusion Matrix - Ensemble Model')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "plt.show()"
            ]
        }\n",
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}